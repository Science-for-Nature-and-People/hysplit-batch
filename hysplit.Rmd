---
title: "hysplit"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Loading libraries
library(tidyverse)
library(lubridate)
library(foreach)

```

## Paths and files

Because we are relying on a lot of large files, we will be relying on different file paths to access your user's github repo, the shared project directory on the server (Aurora), and creating a new directory to create the necessary hysplit files in

For the large .ARL files, we will be creating Symlinks (symbolic link), which will reference the original files without having to copy them over. We do this because hysplit requires the .ARLs to be in the same folder as the other files, but they are time-consuming to copy.

```{r}
# creating file paths to different directories

# github repo directory
aurora_user <- "klope" # user folder name on Aurora (commonly your last name)
repo_dir <- file.path("/home", aurora_user, "R/hysplit-batch") # creates a file path to your github repo to reference below

# shared project folder on aurora
shared_dir <- "/home/shares/snapp-wildfire/HYSPLIT_samplefiles/" # same for all Aurora users

# folder to save model files in your home directory
run_dir <- "~/run2" # the name of your folder, can change to whatever you prefer
dir.create(run_dir, showWarnings = FALSE) # creates the folder (will not copy over if you run again)

# Copying ASCDATA.CFG file from the shared project directory
file.copy(file.path(shared_dir,"ASCDATA.CFG"), run_dir, overwrite = TRUE)

```

## Loop Setup
```{r}

# Start cluster to use for parallelization
nb_cores <- 12  # Aurora has 96 cores
cl <- parallel::makeCluster(nb_cores)
doParallel::registerDoParallel(cl)

# list of ARL files that the loop will cycle through. 
# Must match the names of the .ARL files
# Will use in the created file names (Ex: cdumb.June, SETUP.Aug)
arl_files <- c("June", "July", "Aug")

```

## Hysplit Loop

This loop runs in parallel using the foreach() function. For each month, it:
1) Copies over the EMITMES file
2) Creates the SETUP file
3) Creates the CONTROL file
4) Runs the hysplit model using the system() command

```{r}
foreach(model_run = arl_files) %dopar% {
  
  # create Symlinks of .ARL files into the working directory
  # uses system() to run terminal command
  system(sprintf("ln -s /home/shares/snapp-wildfire/HYSPLIT_samplefiles/%s %s", paste0(model_run, ".ARL"), paste0(run_dir, "/", model_run, ".ARL")))

  # reading in the functions from the "hysplit_batch_functions" script
  source(file.path(repo_dir,"hysplit_batch_functions.R"))

  # copy the EMITIMES files
  emitimes_file <- file.path(shared_dir, paste0("EMITIMES_", tolower(model_run)))
  emitimes_run <- file.path(run_dir, paste0("EMITIMES", ".", model_run))
  file.copy(emitimes_file, emitimes_run, overwrite = TRUE)

  # create the SETUP file
  create_setup <- create_setup(run_dir, extension = model_run, dir_templates =  file.path(repo_dir,"file_templates"))

  # Get information from EMITIMES file that is needed in the CONTROL file
  control_info <- read_emitimes(emitimes_run)
  control_locations <- control_info$locations %>%
    dplyr::select(LAT, LON)

  # Create the CONTROL file
  control_filename <- file.path(run_dir, "CONTROL")
  create_control(control_filename,
                 control_info$date,
                 control_locations,
                 control_info$runtime,
                 arl_file = paste0(model_run, ".ARL"),
                 "./",
                 extension = model_run,
                 dir_templates =  file.path(repo_dir,"file_templates"))


  #### Run the model #####
  repo <- getwd() # saves current working directory
  setwd(run_dir) # saves working directory to the run folder
  system(sprintf("../hysplit/5.0.0/exec/hycs_std %s", model_run)) # runs the command line function for hysplit
  setwd(repo) # resets the working directory

}

# stop cluster to end parellelization
parallel::stopCluster(cl)

system(sprintf("ln -s /home/shares/snapp-wildfire/HYSPLIT_samplefiles/%s %s", paste0("July", ".ARL"), paste0(run_dir, "/", "July", ".ARL")))

```

